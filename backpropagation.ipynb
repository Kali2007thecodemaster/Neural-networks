{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c823203f",
   "metadata": {},
   "source": [
    "# MATHEMATICAL IMPLEMENTATION OF A FEED FORWARD NEURAL NETWORK WITH BACKPROPAGATION\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This implementation demonstrates the mathematical foundations of backpropagation in a fully connected neural network using Python Numpy and Matplotlib for visualization. Our network processes 3-dimensional feature vectors through two hidden layers containing 4 and 3 neurons respectively, producing scalar predictions for regression targets. Using sigmoid activations and mean squared error loss, we explicitly derive and implement the gradient flow through each layer using the chain rule. This transparent, framework-free approach illuminates the mathematical principles underpinning modern deep learning optimizers while providing insight into how neural networks learn representations from data through iterative parameter updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c271c1",
   "metadata": {},
   "source": [
    "## Step 1: Importing the necessary libraries\n",
    "\n",
    "We begin by importing the necessary computational libraries and establishing the mathematical framework for our neural network implementation. NumPy provides efficient array operations essential for vectorized computations of forward propagation and gradient calculations, while Matplotlib enables visualization of the optimization trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4794e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae32e7b",
   "metadata": {},
   "source": [
    "## Step 2: Defining the Neural Network Architecture  \n",
    "\n",
    "Before implementing the feedforward and backpropagation processes, we define the structural parameters of our neural network.  \n",
    "Each variable specifies the number of neurons in a given layer, determining how data flows and transforms through the network.  \n",
    "\n",
    "- **sample_size:** number of training samples (rows in our dataset)  \n",
    "- **input_size:** number of input features for each sample  \n",
    "- **hidden1_size:** number of neurons in the first hidden layer  \n",
    "- **hidden2_size:** number of neurons in the second hidden layer  \n",
    "- **output_size:** number of neurons in the output layer  \n",
    "\n",
    "These dimensions guide the shape of weight matrices and bias vectors during initialization, ensuring that matrix multiplications remain dimensionally consistent throughout forward and backward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "94de9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5 #number of samples\n",
    "input_size = 3 #number of feautures of the input layer\n",
    "hidden1_size = 4 #number of nodes of the 1st hidden layer\n",
    "hidden2_size = 3 #number of nodes of the 2nd hidden layer\n",
    "output_size = 1 #number of nodes of the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3abc6c3",
   "metadata": {},
   "source": [
    "## Step 3: Defining Activation and Loss Functions  \n",
    "\n",
    "Activation and loss functions are fundamental components of a neural network’s learning mechanism.  \n",
    "\n",
    "- The **sigmoid activation function** introduces nonlinearity, allowing the network to model complex relationships beyond simple linear mappings.  \n",
    "- Its **derivative**,is essential during backpropagation to propagate gradients backward through the network efficiently.  \n",
    "- The **Mean Squared Error (MSE)** serves as the cost function, quantifying the difference between predicted outputs.  Minimizing this loss through gradient descent drives the learning process.  \n",
    "\n",
    "Together, these functions establish the mathematical foundation for both forward propagation and gradient-based optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5bc8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation function\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "#Derivative of the activation function\n",
    "def dsigmoid(h):\n",
    "    return h*(1-h)\n",
    "#Loss function (Mean squared Error)\n",
    "def mse(Y_hat, Y_true):\n",
    "    return 0.5*np.mean((Y_hat - Y_true)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e88c4a",
   "metadata": {},
   "source": [
    "## Step 4: Initializing Weights and Biases  \n",
    "\n",
    "We initialize the network parameters — weights and biases — for each layer using random values.  \n",
    "\n",
    "- **Weights** (w1, w2, w3) determine the strength of the connections between neurons across layers.  \n",
    "- **Biases** (b1, b2, b3) allow each neuron to shift its activation independently of the input, improving model flexibility.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "ce4263f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the parameters\n",
    "\n",
    "#Hidden Layer1\n",
    "w1 = np.random.rand(input_size, hidden1_size)\n",
    "b1 = np.random.rand(1, hidden1_size)\n",
    "#hidden Layer2\n",
    "w2 = np.random.rand(hidden1_size, hidden2_size)\n",
    "b2 =  np.random.rand(1, hidden2_size)\n",
    "#output Layer\n",
    "w3 = np.random.rand(hidden2_size, output_size)\n",
    "b3 = np.random.rand(1, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ab6a4",
   "metadata": {},
   "source": [
    "## Step 5: Generating Input and Target Data  \n",
    "\n",
    "To test the network, we create synthetic data to serve as input features and corresponding target outputs:  \n",
    "\n",
    "- **Input matrix (X):** Each of the `sample_size` rows represents one observation, and each column corresponds to one input feature.  \n",
    "- **Target matrix (Y):** Contains the expected outputs that the network will attempt to approximate through training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "7122351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the inputs\n",
    "X = np.random.rand(sample_size, input_size)\n",
    "Y = np.random.rand(sample_size,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ff836",
   "metadata": {},
   "source": [
    "## Step 6: Setting Training Hyperparameters  \n",
    "\n",
    "Before training the network, we define essential **hyperparameters** that control the learning process:\n",
    "\n",
    "- **Learning rate (lr):** Determines the step size used to update weights during gradient descent.  \n",
    "  A small value leads to slow but stable convergence, while a large value risks overshooting the minimum of the loss function.  \n",
    "- **Epochs:** Represents the total number of complete passes through the training dataset.  \n",
    "  Increasing this value allows the network to refine its parameters over time.  \n",
    "- **Loss tracking:** An empty list is initialized to record the loss value at each epoch, allowing visualization of the optimization trajectory after training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training parameters\n",
    "lr = 0.01\n",
    "epochs = 5000\n",
    "#Tracking the loss function\n",
    "loss_track = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0c9d4",
   "metadata": {},
   "source": [
    "## Step 7: Training the Neural Network  \n",
    "\n",
    "This step combines **forward propagation**, **loss computation**, and **backpropagation** into a complete training cycle that iteratively updates the network’s parameters.\n",
    "\n",
    "### 1. Forward Propagation  \n",
    "- Each layer performs a linear transformation followed by a nonlinear activation.  \n",
    "- Information flows sequentially from the input through both hidden layers to the output.  \n",
    "- The network’s prediction **Y_hat**is obtained at the output layer using the sigmoid activation function.  \n",
    "\n",
    "### 2. Loss Computation  \n",
    "- The **Mean Squared Error (MSE)** quantifies how far the predictions are from the target outputs.  \n",
    "- This scalar loss value guides how parameters should be adjusted to minimize prediction error.  \n",
    "\n",
    "### 3. Backpropagation  \n",
    "- The error is propagated backward through the network using the **chain rule**.  \n",
    "- Partial derivatives of the loss with respect to weights and biases are computed layer by layer:  \n",
    "  - The output layer gradients measure the sensitivity of the final prediction to each weight.  \n",
    "  - The hidden layers’ gradients capture how each neuron contributed to the final error.  \n",
    "- These gradients are then used to update the parameters in the direction that reduces the loss.  \n",
    "\n",
    "### 4. Parameter Update  \n",
    "- Each weight and bias is adjusted using **gradient descent** with the learning rate (`lr`), controlling how aggressively the model learns.  \n",
    "- Over many epochs, this iterative process minimizes the loss function, improving the model’s predictions.  \n",
    "\n",
    "Together, these steps represent the complete **learning algorithm** that enables the neural network to approximate nonlinear relationships from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "004329c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "for epoch in range(epochs):\n",
    "    #=======Forward pass========\n",
    "    #Hidden Layer1\n",
    "    z1 = np.dot(X,w1)+b1\n",
    "    h1 = sigmoid(z1)\n",
    "    #Hidden Layer2\n",
    "    z2 = np.dot(h1,w2)+b2\n",
    "    h2 = sigmoid(z2)\n",
    "    #Output Layer\n",
    "    z3 = np.dot(h2,w3)+b3\n",
    "    h3 = sigmoid(z3)\n",
    "    Y_hat = h3\n",
    "    \n",
    "    #=======Loss computation========\n",
    "    Loss = mse(Y_hat, Y)\n",
    "    loss_track.append(Loss)\n",
    "    \n",
    "    #=======Backpropagation========\n",
    "    #Output Layer\n",
    "    dh3 = Y_hat - Y\n",
    "    dz3 = dh3 * dsigmoid(h3)\n",
    "    dw3 = np.dot(h2.T, dz3)\n",
    "    db3 = np.sum(dz3, axis = 0, keepdims = True)\n",
    "    #Hidden Layer2\n",
    "    dh2 = np.dot(dz3,w3.T)\n",
    "    dz2 = dh2 * dsigmoid(h2)\n",
    "    dw2 = np.dot(h1.T, dz2)\n",
    "    db2 = np.sum(dz2, axis = 0, keepdims= True)\n",
    "    #Hidden Layer2\n",
    "    dh1 = np.dot(dz2,w2.T)\n",
    "    dz1 = dh1 * dsigmoid(h1)\n",
    "    dw1 = np.dot(X.T, dz1)\n",
    "    db1 = np.sum(dz1, axis = 0, keepdims = True)\n",
    "    \n",
    "    #Update the paramaters\n",
    "    w3 -= lr * dw3\n",
    "    b3 -= lr * db3\n",
    "    w2 -= lr * dw2\n",
    "    b2 -= lr * db2\n",
    "    w1 -= lr * dw1\n",
    "    b1 -= lr * db1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc42138",
   "metadata": {},
   "source": [
    "# Step 8: Evaluating model performance\n",
    "\n",
    "Model evaluation quantifies predictive accuracy and validates training effectiveness. The accuracy calculation uses **1−mean(|Y_hat - Y|)** to measure average prediction correctness across all samples. Comparing predictions **Y_hat** against true values **Y** reveals the model's actual performance on the training data, while percentage formatting provides an intuitive measure of success that facilitates interpretation and comparison with other models. \n",
    "These metrics transform the optimized weights into concrete evidence of the neural network's learning capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "581bb7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true values are: \n",
      " [[0.33734555]\n",
      " [0.01932763]\n",
      " [0.1243684 ]\n",
      " [0.41364267]\n",
      " [0.49286458]]\n",
      "The prediction is: \n",
      "[[0.27733806]\n",
      " [0.27523915]\n",
      " [0.27917819]\n",
      " [0.27938524]\n",
      " [0.27598113]]\n",
      "the accuracy of neural network is: 83.56 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the model\n",
    "accuracy = (1 - np.mean(abs(Y_hat - Y)))*100\n",
    "print(f'The true values are: \\n {Y}')\n",
    "print(f'The prediction is: \\n{Y_hat}')\n",
    "print(f'the accuracy of neural network is: {accuracy:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3920707",
   "metadata": {},
   "source": [
    "# Step 9: Visualizing training dynamics\n",
    "\n",
    "Tracking and plotting the loss function throughout training provides critical insights into the optimization process. The **loss trajectory**, displayed on a logarithmic scale, reveals how effectively gradient descent minimizes the Mean Squared Error over successive epochs. A steadily decreasing curve indicates successful learning, while plateaus or oscillations may signal issues with learning rate or convergence. This visualization transforms abstract numerical optimization into an interpretable diagnostic tool, allowing practitioners to assess training stability, detect overfitting or underfitting, and validate that the network has achieved satisfactory convergence before deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a611a343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the loss function\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(loss_track, linewidth = 2)\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.title('Training Loss over time')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss(MSE)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66704ab9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This implementation successfully demonstrates the mathematical foundations of neural network learning through explicit backpropagation. By constructing a two-hidden-layer network from first principles using only NumPy, we traced the complete gradient flow from output error back through each layer using the chain rule. The network achieved convergence through iterative weight updates driven by gradient descent, with the loss trajectory confirming successful optimization. This transparent, framework-free approach reveals the elegant mathematical machinery underlying modern deep learning: how nonlinear activations enable complex function approximation, how the chain rule enables efficient gradient computation, and how simple iterative updates gradually sculpt network parameters to minimize prediction error. While production systems employ sophisticated frameworks and optimizations, understanding these core principles—forward propagation, loss computation, gradient calculation, and parameter updates—remains essential for developing intuition about neural network behavior, diagnosing training issues, and designing effective architectures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
